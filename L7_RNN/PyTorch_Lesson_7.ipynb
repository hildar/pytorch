{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6_vcBAmo6k9"
   },
   "source": [
    "# Рекурентные сети для обработки последовательностей\n",
    "\n",
    "Вспомним все, что мы уже знаем про обработку текстов:\n",
    "- Компьютер не понимает текст, поэтому нам нужно его как-то закодировать - представить в виде вектора\n",
    "- В тексте много повторяющихся слов/лишний слов - нужно сделать препроцессинг:\n",
    "    - удалить знаки препинания\n",
    "    - удалить стоп-слова\n",
    "    - привести слова к начальной форме (**стемминг** и **лемматизация**)\n",
    "    \n",
    "    \n",
    "- После этого мы можем представить наш текст (набор слов) в виде вектора, например, стандартными способами:\n",
    "    - **CounterEncoding** - вектор длины размер нашего словаря\n",
    "        - есть словарь vocab, который можем включать слова, ngram-ы\n",
    "        - каждому документу $doc$ ставим в соответствие вектор $vec\\ :\\ vec[i]=1,\\ если\\ vocab[i]\\ \\in\\ doc$\n",
    "    - **TfIdfVectorizer** - вектор длины размер нашего словаря\n",
    "        - есть словарь vocab, который можем включать слова, ngram-ы\n",
    "        - каждому документу $doc$ ставим в соответствие вектор $vec\\ :\\ vec[i]=tf(vocab[i])*idf(vocab[i]),\\ если\\ vocab[i]\\ \\in\\ doc$\n",
    "    \n",
    "        $$ tf(t,\\ d)\\ =\\ \\frac{n_t}{\\sum_kn_k} $$\n",
    "        $$ idf(t,\\ D)\\ =\\ \\log\\frac{|D|}{|\\{d_i\\ \\in\\ D|t\\ \\in\\ D\\}|} $$\n",
    "        \n",
    ", где \n",
    "- $n_t$ - число вхождений слова $t$ в документ, а в знаменателе — общее число слов в данном документе\n",
    "- $|D|$ — число документов в коллекции;\n",
    "- $|\\{d_i\\ \\in\\ D\\mid\\ t\\in d_i\\}|$— число документов из коллекции $D$, в которых встречается $t$ (когда $n_t\\ \\neq\\ 0$).\n",
    "\n",
    "\n",
    "\n",
    "Это база и она работает. Мы изучили более продвинутые подходы: эмбединги и сверточные сети по эмбедингам. Но тут есть проблема: любой текст - это последовательность, ни эмбединги, ни сверточные сети не работают с ним как с последовательностью. Так давайте попробуем придумать архитектуру, которая будет работать с текстом как с последовательностью, двигаясь по эмбедингам и как-то меняя их значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv0Vrhdbp5Dr"
   },
   "source": [
    "# 1. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH2QSxGUp5Ds"
   },
   "source": [
    "Рассмотрим архитектуру, которая позволяет решать задачи свзанные с последовательностями. Будем изучать по мотивам известной [статьи](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) от [Андрея Карпатова](http://karpathy.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1PawJNIp5Dt"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1hYDawc813JLg6vHdvVlbZH-S7ADtwGX6' width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aiPfu8Dp5Dt"
   },
   "source": [
    "1) На первой картинке представлен пример нашей обычной нейронной сети. Она что-то получает на вход, что-то с ним делает и выдает выходные значения. Все фиксированных размеров.  \n",
    "2) Мы познакомимся с архитектурой, которая может на вход получить один вход, а на выходе иметь несколько.   \n",
    "3) И наоборот, на вход подать несколько (причем неизвестного количества), а на выходе одно значение. Один из примеров такой задачи - это [sentimental analysis](https://monkeylearn.com/sentiment-analysis/). Т.е. на вход идет некое предложение, а на выход мы хотим получить одно значение. Например, оно позитивное или негативное или еще какое.  \n",
    "4) Или же могут быть варианты многие ко многим. На вход подаем некоторое переменное количество параметров, а на выходе другое тоже переменое количество параметров.  Пример такой задачи - это перевод текста (перевод на другие иностранные языки). Или другой вариант многие ко многим - это когда количество параметров на входе фиксированно и соотвествует выходу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FoWcMjep5Du"
   },
   "source": [
    "Собственно, как выглядит архитектура, которая позволяет работать с таким переменным количетсвом параметров на вход и на выход?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrZBWJ-Np5Dv"
   },
   "source": [
    "## 1.1 Основная Идея\n",
    "Возьмем обычную нейронную сеть. \n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1ccQJE-E40zNb8U1pfalvxdMXqabepwZp' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD88_29ip5Dw"
   },
   "source": [
    "У нас есть вход, выход и т.д. Посередине один линейный слой. И он выдает какой-то сигнал на выходе.  \n",
    "И мы возьмем и начнем этот же сигнал (этот же вектор) подавать на вход сети самой себе на следующем шаге:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ1DReTZp5Dw"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1zPx_5hIX8_1Q0EPEUWjcOn7hNGHgALWi' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c027z4dp5Dx"
   },
   "source": [
    "У нас есть какая-то последовательность данных. Например назовем их a, b, c. Для первого элемента последовательности мы просто прогнали сеть. Чтобы вход скрытого слоя всегда получал одно и тоже значение, мы сначала даем ему просто какой-то нулевой вектор и то что выдал предыдущий слой. А для следующей сети из последовательности мы возьмем то, что выдала сеть на прошлом шаге и передадим ей. Т.е. у такой сети есть возможность передать самой себе в будущем некоторое состояние. Ну и продолжим так делать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymEz8Wojp5Dx"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1pHueSBIHuRxh1DJTfkQny007g3dh_pCw' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVYcOqQIp5Dy"
   },
   "source": [
    "Мы тренируем такую систему, где промежуточный выход с сети прошлого шага дают на вход сети на следующем шаге. Это значит, что она может выучить некоторое  представление входа. Как-то его закодировать в вектор и передать самой себе на следующем шаге, чтобы знать, что происходило раньше. И таким образом результирующий выход сети, он уже зависит от всей накопленной последовательности. И это дает нам возможность на основе всей последовательности выдать выход.  \n",
    "И тот факт, что мы даем на вход сети самой себе - это некоторая рекурсия и поэтому такая архитектура называется так, как она называется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8Q3s5Ecp5Dy"
   },
   "source": [
    "## 1.2 Давайте посмотрим как это примерно выглядит в коде:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7T_wEG9p5Dz"
   },
   "source": [
    "```\n",
    "\n",
    "class RNN:\n",
    "  # ...\n",
    "  def step(self, x):\n",
    "    # update the hidden state\n",
    "    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))\n",
    "    # compute the output vector\n",
    "    y = np.dot(self.W_hy, self.h)\n",
    "    return y\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8WAsIgzp5D0"
   },
   "source": [
    "Вот наш шаг - т.е. forward, прямой проход. Он выглядит следующим образом:  \n",
    "Мы делаем матричное произведение весов W и текущего состояния h и добавляем тоже произведение весов W на вход x. и получаем новый h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thHcGUkbp5D0"
   },
   "source": [
    "Давайте о том же самом, только на другой картинке:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA43syrZp5D1"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1cJVaUAJZdjaFw65zR_2QyJ9nEgmMV8td' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hNJc-xVp5D1"
   },
   "source": [
    "У нас есть набор X, где t - элементы последовательности. Мы сливаем h и X_t  вместе, прогоняем через слой, через тангенсальную функцию активации. и получаем следующие h.\n",
    "\n",
    "Почему tanh? А например не ReLU? Второй всегда отрезает отрицательную часть сигнала. И это имеет такое последствие, что сигнал, который проходит через сеть никогда не сможет стать отрицательным. И это значит, что когда через много слоев проходим - то сигнал может только расти. Поэтому пользуются именно tanh, что бы были возможности получить и плюс, и минус."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bJvuRlEp5D2"
   },
   "source": [
    "## 1.3 Количество слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edqD0mlsp5D2"
   },
   "source": [
    "Можно так же настэкать большое количество слоев, как и везде.   \n",
    "Вот так выглядит рекурентная сеть с несколькими слоями:\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=175Ij-M6mGkW7zo2n-_u9fM-cPezPcTo8' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9zA9Qx4p5D3"
   },
   "source": [
    "То есть обычным образом можно прогнать сигнал через слои сети. И при этом каждый из слоев выдает своему эквивалентному слою в следующей итерации сети некоторое скрытое состояние. Чем больше слоев, тем сеть обладает большей обобщающей способностью. И каждый слой на своем уровне понимания может себе в будущем передать состояние. При этом веса у каждого эквивалентного слоя одни и те же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V8xOuWsp5D3"
   },
   "source": [
    "## 1.4 Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNiJbLa3p5D4"
   },
   "source": [
    "Вот у нас есть задача генерации текста. Разберем наш текст на последовательность символов.  \n",
    "\n",
    "[BOS], \"h\", \"e\", \"l\", \"l\", \"o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkP-h85Kp5D4"
   },
   "source": [
    "У нас будет специальный вспомогательный символ BOS - begin of sentense.  \n",
    "\n",
    "И мы будем тренировать сеть, такую, что по каждому элементу будем предсказывать следующий. Т.е.\n",
    "\n",
    "[BOS] -> 'h'  \n",
    "'h' -> 'e'  \n",
    "'e' -> 'l'  \n",
    "'l' -> 'l'  \n",
    "'l' -> 'o'  \n",
    "'o' -> [EOS]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z08jSv7rp5D5"
   },
   "source": [
    "Вот пример как это может выглядеть:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlyMQcgZp5D5"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1h6ABYQwTIxCAKdxjgRiIjkf_Go1qvojW' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYNwKiK5p5D6"
   },
   "source": [
    "Элементы нашей последовательности мы можем представить как one-hot представление. Оно все проходит и на выходе предсказывает следующий символ в one-hot представлении. И если это дело долго тренировать, то на выходе такая сеть начинает генерировать реально хороший текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O81r569ReR-",
    "outputId": "59d59162-4b09-4209-868f-4c21c58c8d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stop-words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 39.3 MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: stop-words, docopt\n",
      "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=000f288bb4e7da0dd39177cc6d4e60828446f1241a5775130f7e67243381a942\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=1332ffac7d97139ae436dd3d639db1e65078405c4d91f6678a95e9913602fae4\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built stop-words docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, stop-words, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 stop-words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpooDtBoo6lB"
   },
   "outputs": [],
   "source": [
    "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzAye9tJRPaH"
   },
   "source": [
    "Ссылка на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAcbPjyeRSkQ",
    "outputId": "e7a3d712-b365-4a46-e079-e128318a54e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-22 15:40:10--  https://drive.google.com/uc?export=download&id=1Mev_EEput0LlBj8MDHIJkBtahlJ6J901\n",
      "Resolving drive.google.com (drive.google.com)... 142.251.12.113, 142.251.12.138, 142.251.12.139, ...\n",
      "Connecting to drive.google.com (drive.google.com)|142.251.12.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-14-c0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uednrkbn9fsu2h997psdhj069h3o39to/1661182800000/14904333240138417226/*/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901?e=download&uuid=2e32c92d-b832-4b4f-9060-d9c3c0294ea4 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-22 15:40:15--  https://doc-14-c0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uednrkbn9fsu2h997psdhj069h3o39to/1661182800000/14904333240138417226/*/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901?e=download&uuid=2e32c92d-b832-4b4f-9060-d9c3c0294ea4\n",
      "Resolving doc-14-c0-docs.googleusercontent.com (doc-14-c0-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
      "Connecting to doc-14-c0-docs.googleusercontent.com (doc-14-c0-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10733963 (10M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  10.24M  18.7MB/s    in 0.5s    \n",
      "\n",
      "2022-08-22 15:40:17 (18.7 MB/s) - ‘data.zip’ saved [10733963/10733963]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://drive.google.com/uc?export=download&id=1Mev_EEput0LlBj8MDHIJkBtahlJ6J901' -O data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjAuCojERXaa",
    "outputId": "c2e4261c-affe-4f90-d9e0-d42a47225316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: train.csv               \n",
      "  inflating: val.csv                 \n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUCk-5M2yg3S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_val = pd.read_csv(\"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v7G2jv7Ro6lC",
    "outputId": "c0f1d4e8-0db5-464b-eeb9-4a57f7d53b00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6e4f52fc-8bd1-4c29-82da-b3f9ced3b708\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e4f52fc-8bd1-4c29-82da-b3f9ced3b708')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6e4f52fc-8bd1-4c29-82da-b3f9ced3b708 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6e4f52fc-8bd1-4c29-82da-b3f9ced3b708');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfMrjVd6o6lD"
   },
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "puncts = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in puncts)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"не\\s\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZHFblHvRmiJ",
    "outputId": "ae3af6bf-c7a1-4738-9fae-a50737b8d75e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181467/181467 [03:53<00:00, 778.11it/s]\n",
      "100%|██████████| 22683/22683 [00:27<00:00, 829.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4o9QgmWI3Pw"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"text\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hed2ySbwJH6B",
    "outputId": "d633a131-b87f-4369-ecf0-bfdf6c7cc7fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ8T0fwYJYJX"
   },
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crczOvHcSlN2"
   },
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 20\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 5\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXOLVK1tJLT8"
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qCQH5nIJoiB"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRQ-6wwjJrGo",
    "outputId": "246a6af8-a5f1-42fc-c4e8-6031bc928e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'd',\n",
       " 'хотеть',\n",
       " 'новый',\n",
       " 'завтра',\n",
       " 'мой',\n",
       " 'вообще',\n",
       " 'хороший',\n",
       " 'любить',\n",
       " 'немочь']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "# vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OULZgvkJzpj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "\n",
    "    padding = [0] * (maxlen-len(result))\n",
    "    return result[-maxlen:] + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqHlf5nNJ2hl",
    "outputId": "cdb403fd-4b5d-443d-a1fc-f0ce6bf91e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 111 ms, total: 20 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lI4NUg_TJ6NK",
    "outputId": "c9e2e9a7-3177-4cc2-b9b7-9ca703679db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181467, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QlLvXd9KDf3",
    "outputId": "db81449e-17cc-48ba-d139-1dafb2407d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 196, 429, 161,   5,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqXHY5ARSxoV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNTWTaxlSy3N"
   },
   "outputs": [],
   "source": [
    "train_dataset = DataWrapper(x_train, df_train['class'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DataWrapper(x_val, df_val['class'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvtTpOFZPp1O"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=175Ij-M6mGkW7zo2n-_u9fM-cPezPcTo8' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O38bou70o6lG"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class RNNFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=2, batch_first=True, )\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        rnn_out, ht = self.rnn(x) \n",
    "        # rnn_out: тензор с выходными фичами с последнего слоя для каждого t\n",
    "        # h_t: тензор с последними скрытыми состояниями по слоям\n",
    "\n",
    "        if self.use_last:\n",
    "            last_tensor = rnn_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(rnn_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        \n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XE-LnMho6lH"
   },
   "outputs": [],
   "source": [
    "rnn_init = RNNFixedLen(max_words, 128, 20, use_last=False)\n",
    "optimizer = torch.optim.Adam(rnn_init.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OXY71G4veHj",
    "outputId": "4a2c8d8b-6d9b-4ffc-fd77-eae3e9bb78a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNFixedLen(\n",
      "  (embeddings): Embedding(2000, 128, padding_idx=0)\n",
      "  (rnn): RNN(128, 20, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Parameters: 259861\n"
     ]
    }
   ],
   "source": [
    "print(rnn_init)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in rnn_init.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "NLj6P7Vxt8GY",
    "outputId": "25204e84-f5d8-41ff-a28c-4469843acf10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "rnn_init.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYvioFNjut4i",
    "outputId": "9dc29ed9-afac-4ec9-c3f7-949c780efa02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [355/355]. Loss: 0.549. Acc: 0.619. Test loss: 0.559. Test acc: 0.683\n",
      "Epoch [2/5]. Step [355/355]. Loss: 0.545. Acc: 0.685. Test loss: 0.607. Test acc: 0.701\n",
      "Epoch [3/5]. Step [355/355]. Loss: 0.553. Acc: 0.698. Test loss: 0.592. Test acc: 0.703\n",
      "Epoch [4/5]. Step [355/355]. Loss: 0.577. Acc: 0.703. Test loss: 0.589. Test acc: 0.706\n",
      "Epoch [5/5]. Step [355/355]. Loss: 0.588. Acc: 0.707. Test loss: 0.534. Test acc: 0.706\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "rnn_init = rnn_init.to(device)\n",
    "rnn_init.train()\n",
    "th = 0.5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    rnn_init.train()\n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_init(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    rnn_init.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "          f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "          f'Loss: {loss:.3f}. ' \\\n",
    "          f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = rnn_init(data[0].to(device))\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m91E6Wo7o6lI"
   },
   "source": [
    "# Какие проблемы у рекурентных сетей?\n",
    "\n",
    "- затухают градиенты\n",
    "- медленно, нужно всегда дойти до конца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4USjc6V8p5D7"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=17VtpKmVwlu0a7UjGbNfT0cjljfpsuKqU' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLeflGiYp5D7"
   },
   "source": [
    "Вот у нас есть рекуррентная сеть. Она дает себе на вход значение на следующем шаге. Когда мы ее тренируем, мы как бы разматываем всю эту систему в одну большую сеть, которая прогоняет все элементы последовательности. И у всех слоев сетей в разные промежутки времени одни и те же веса. Соответсвенно, проходясь обратным распространением по этим сетям все это вместе складываем и применяем. Так происходит обучение.  \n",
    "\n",
    "И от этого возникает проблема длинных зависимостей. Т.е. например, то что произошло в начале последовательности, может повлиять на то, что произойдет в конце этой последовательности. Для этого нужно, что бы сигнал во время тренировки протек по длинному пути всей последовательности. А у нас тут очень много матричных умножений на одну и ту же матрицу. Например, у нас 100 таких шагов. Что бы градиент прошел обратно, он будет сто раз умножен на одну и ту же матрицу. И это критично. Т.к. если, например, эта матрица какой-то один сигнал увеличивает чуть. То после того, как оно пройдет 100 раз, сеть этот сигнал сделает огромным. А у нас там tanh, который этот сигнал совсем убьет, т.к. сделает его очень большшим. \n",
    "\n",
    "Поэтому в такой простой формулировке, большие последовательности не получается тренировать. И на практике используют другие архитектуры, которые эту проблему решают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsZkNJMnOK5B"
   },
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Hyperbolic_Tangent.svg/2560px-Hyperbolic_Tangent.svg.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDd94jEip5D8"
   },
   "source": [
    "# 2. LSTM. Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fdLf2TNp5D8"
   },
   "source": [
    "[оригинальная статья. 1997](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6EKzzNnp5D9"
   },
   "source": [
    "Автор статьи [Юрген Шмидхубер](https://ru.wikipedia.org/wiki/%D0%A8%D0%BC%D0%B8%D0%B4%D1%85%D1%83%D0%B1%D0%B5%D1%80,_%D0%AE%D1%80%D0%B3%D0%B5%D0%BD). Первая реализации ее случилась только после несколько лет после ее публикации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlfoNQbCp5D9"
   },
   "source": [
    "[статья](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), которая объясняет что там происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX8mgyJHp5D9"
   },
   "source": [
    "[перевод](https://alexsosn.github.io/ml/2015/11/17/LSTM.html) статьи выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuIfH7rrp5D9"
   },
   "source": [
    "Вот как можно представить схему LSTM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD_UR8Dvp5D-"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1h2F2sb-DgesuXRtLa4GbxH8QI_4swaE7' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pao9YzkVp5D-"
   },
   "source": [
    "Выглядит запутанно. Давайте распутывать.  \n",
    "\n",
    "Основная идея.  \n",
    "\n",
    "Теперь на каждом шаге мы передаем не один вектор, а два. Один из них (нижний) - это то самый h, который пойдет на вход следующему слою. А кроме этого, мы будем передавать, так называемое self-state. Назовем этот вектор - с. И вот h будет теперь проходить через много нелинейностей, умножаться на матрицы и будет испытывать все те же проблемы, которые мы обсуждали выше.  \n",
    "\n",
    "А с будет как можно больше напрямую передаваться из прошлого состояния в следующее. Мы по нему будем очень аккуратно делать апдейты, что бы он очень плавно перетекал из одного состояния в другое.  \n",
    "\n",
    "### 2.1 Как это выглядит подробнее:  \n",
    "\n",
    "Внутри есть мнгого разных гейтов - некоторый вектор коэффициентов, которые соответсвуют той же размерности что и вход на них.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDZyDDREtgFF"
   },
   "source": [
    "#### **Forget gate**\n",
    "\n",
    "Первый шаг в LSTM - это решить, от какой информации мы хотим избавиться. Это решение принимает слой с сигмоидой, который называется \"forget gate layer.\" (гейт забывания). Он принимает во внимание $h_{t−1}$ и $x_t$, а на выходе даёт значение между 0 и 1 для каждого числа в состоянии ячейки $C_{t−1}$. 1 значит \"полностью сохрани это\", а 0 - \"полностью забудь это\".\n",
    "\n",
    "Пример забывания - языковая модель пытается предсказать следующее слово базируясь на предыдущих. Здесь модель может запоминать род объекта, чтобы использовать правильное образование слов. Когда мы видим новый объект, то нужно забыть род предыдущего объекта. *(Животное не переходило дорогу, потому что оно устало)*\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1oYGrHhH6y4_DtwRcKJDjzvYVChPEMblR'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg2XTz8Bu2vq"
   },
   "source": [
    "#### **Input gate**\n",
    "\n",
    "Следующий шаг - решить, какую информацию мы должны хранить в состоянии ячейки. Шаг состоит из двух частей. Первая - слой сигмоиды, называемый \"input gate layer\" (входной гейт), который решает какие значения будут обновляться. Вторая - слой с тангенсом, который создает вектор значений $\\tilde{C}_t$, которые будут добавляться к состоянию ячейки. Используем tanh, потому что нам хочется что бы эта добавка могла пойти и в + и в -. \n",
    "\n",
    "\n",
    "С примером языковой модели, мы бы хотели добавлять род нового объекта в состояние ячейки, чтобы заменить старый род, который мы забудем. *(Животное не переходило дорогу, потому что оно устало)*\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1kb4hs0Y1cLb55sl-iRPsxMuNzLlu5qXb'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWAx-0CMwRMP"
   },
   "source": [
    "#### **Update cell state**\n",
    "\n",
    "Сейчас самое время, чтобы обновить старое состояние $C_{t−1}$ в новое состояние $C_t$. Предыдущие шаги уже решили, что делать, нужно только сделать это.\n",
    "\n",
    "Умножаем старое состояние на $f_t$, тем самым забывая те вещи, которые хотели забыть, затем прибавляем $i_t∗\\tilde{C_t}$. Это новое значение состояния ячейки, которое отмасштабировано в зависимоcти от того, насколько мы хотим обновить новое значение.\n",
    "\n",
    "В языковой модели, это момент, где мы выкидываем информацию о роде старого объекта и добавляем новую информацию о роде нового объекта. *(Животное не переходило дорогу, потому что оно устало)*\n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1oKlTuYYRwdnvfMUQW0FjHRWgtHy0xl1M'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuJxpzKLzviM"
   },
   "source": [
    "#### **Output gate**\n",
    "\n",
    "Наконец-то нам нужно решить, что мы отправим на выход. Выход будет базироваться на состоянии ячейки, но с небольшой фильтрацией. Во-первых, прогоним входной сигнал через сигмоиду, которая решает с какой силой дальше пропускать сигнал, во-вторых, прогоняем состояние ячейки через тангенс и умножаем это на сигмоиду, чтобы пропускать дальше только то, что мы решили пропустить.\n",
    "\n",
    "\n",
    "Для языковой модели, которая видит только объект, здесь можем пропустить информацию, связанную с глаголом. Например, на выходе может быть полезно число множественной или единственное у объекта, чтобы знать в какую форму нужно поставить глагол. *(Животное не переходило дорогу, потому что оно устало)*\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=12SBxiBO-knE250rVlTxSYkmGWLjzFHL0'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7IX2EGop5EB"
   },
   "source": [
    "Вот так модуль LSTM выглядит в деталях. Зазубривать все это не обязательно. Основная идея зачем мы все это делаем - это бы мы на следующий шаг передавали два вектора. Один из них h в процессе своего формирования прошел через огромное количество нелинейностей, одних и тех же весов и т.д. и по нему градиент идет ни хорошо, ни плохо.  \n",
    "\n",
    "Зато у этого С вычисления очень прямолинейные. Т.е. он умножен на какое-то число, которое еще и чаще всего 1, в нему была добавка. А функция + очень хороша для градиента. Вот почему:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZvl6VuDp5EB"
   },
   "source": [
    "Вот наш проход с. Вектор с умножается, складывается и идет дальше:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsZy1--4p5EC"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1IcyH_3Ab-KenQ8BgHeOrt44CcJ_1Wb_t' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCtQvFm6p5EC"
   },
   "source": [
    "А вот если все это сложить прошлое со следующим. То видим что мы организовали такой некий highway на котором градиент меньше всего затухает.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1C-EYALdJNO24YPxBhreZv2PitbQFQ73o' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHHwqVeUp5EC"
   },
   "source": [
    "Можно провести аналогию с тем, что происходит на сетях ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hzo6I_kp5EC"
   },
   "source": [
    "Визуализация прохода сигнала по LSTM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKHdgabAp5ED"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1ezEAemVgiEW3POhGjEjIjFdre8I7pri-' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzlCNORAo6lJ"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class LSTMFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, ht = self.lstm(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = lstm_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        # print(out.shape)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w2lHWkue64N"
   },
   "outputs": [],
   "source": [
    "lstm_init = LSTMFixedLen(max_words, 128, 20, use_last=False)\n",
    "optimizer = torch.optim.Adam(lstm_init.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PUisoS9w0rH",
    "outputId": "8ee3b65f-9971-4b05-efbd-da4c6c3fd67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMFixedLen(\n",
      "  (embeddings): Embedding(2000, 128, padding_idx=0)\n",
      "  (lstm): LSTM(128, 20, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Parameters: 271381\n"
     ]
    }
   ],
   "source": [
    "print(lstm_init)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in lstm_init.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qw1Mpj_Co6lJ",
    "outputId": "5c141d01-34fb-45bb-c314-97d1e6b808d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [355/355]. Loss: 0.562. Acc: 0.632. Test loss: 0.585. Test acc: 0.690\n",
      "Epoch [2/5]. Step [355/355]. Loss: 0.590. Acc: 0.692. Test loss: 0.578. Test acc: 0.700\n",
      "Epoch [3/5]. Step [355/355]. Loss: 0.514. Acc: 0.703. Test loss: 0.567. Test acc: 0.702\n",
      "Epoch [4/5]. Step [355/355]. Loss: 0.595. Acc: 0.709. Test loss: 0.551. Test acc: 0.707\n",
      "Epoch [5/5]. Step [355/355]. Loss: 0.537. Acc: 0.712. Test loss: 0.516. Test acc: 0.709\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "lstm_init = lstm_init.to(device)\n",
    "lstm_init.train()\n",
    "th = 0.5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    lstm_init.train()\n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_init(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    lstm_init.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "            f'Loss: {loss:.3f}. ' \\\n",
    "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = lstm_init(data[0].to(device))\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2gbd_Oao6lK"
   },
   "source": [
    "# 3. GRU. Gated Recurrent Unit\n",
    "\n",
    "\n",
    "Какие проблемы всё еще есть с LSTM:\n",
    "\n",
    "- вычислительно сложно -> медленнее\n",
    "- на очень длинных последовательностях все равно затухает градиент\n",
    "\n",
    "\n",
    "Зачем платить больше - уберем некоторые врата (точнее совместим) -> ускоримся, уменьшим число параметров -> GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bf-QQq0p5EE"
   },
   "source": [
    "Но какого-то большого выигрыша от этого нет и наиболее часто применяются LSTM. \n",
    "И GRU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-w0Ykhnp5EE"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=10Q_1hrXcOlpe5WgIq-tuGBScDzaxH_Vl' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtq6UR4co6lK"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class GRUFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, )\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        gru_out, ht = self.gru(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = gru_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ByBMc_5fEo3"
   },
   "outputs": [],
   "source": [
    "gru_init = GRUFixedLen(max_words, 128, 20, use_last=False)\n",
    "optimizer = torch.optim.Adam(gru_init.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkKANTWQx2Yb",
    "outputId": "61c8436a-09d8-4c34-9b67-8bb8d9b8d979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUFixedLen(\n",
      "  (embeddings): Embedding(2000, 128, padding_idx=0)\n",
      "  (gru): GRU(128, 20, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Parameters: 267541\n"
     ]
    }
   ],
   "source": [
    "print(gru_init)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in gru_init.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B09_p9r5x2Yg",
    "outputId": "1935b472-e561-4ead-b232-13ffddd27ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [355/355]. Loss: 0.586. Acc: 0.632. Test loss: 0.617. Test acc: 0.689\n",
      "Epoch [2/5]. Step [355/355]. Loss: 0.539. Acc: 0.695. Test loss: 0.546. Test acc: 0.703\n",
      "Epoch [3/5]. Step [355/355]. Loss: 0.537. Acc: 0.703. Test loss: 0.499. Test acc: 0.704\n",
      "Epoch [4/5]. Step [355/355]. Loss: 0.553. Acc: 0.709. Test loss: 0.490. Test acc: 0.705\n",
      "Epoch [5/5]. Step [355/355]. Loss: 0.525. Acc: 0.712. Test loss: 0.567. Test acc: 0.707\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "gru_init = gru_init.to(device)\n",
    "gru_init.train()\n",
    "th = 0.5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    gru_init.train() \n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gru_init(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    gru_init.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "          f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "          f'Loss: {loss:.3f}. ' \\\n",
    "          f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = gru_init(data[0].to(device))\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
    "            \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajApsdao66hr"
   },
   "source": [
    "# 4. Интересные концепты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VibWuP0jGt4F"
   },
   "source": [
    "## 4.1 Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLDjJ2kkH3iK"
   },
   "source": [
    "Примеры из статьи [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144).\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1uOHQX8AnPGKY6HEDOTRJzVxCiKAHLoJy' width=450>\n",
    "\n",
    "Нужно сжать всю информацию о предыдущих словах в один блок, который представляет собой внутренний слой - переходное состояние из кодировщика в декодировщика, что очень сложная задача, которая приводит к недообучению.\n",
    "\n",
    "И одно из возможных решений - это настакать слои LSTM, один слой LSTM создает вход для другого слоя LSTM:\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1yrBxb5DXZA-LNwNWQdmuF4TNNXqTfNpJ' width=450>\n",
    "\n",
    "Но эту вещь очень тяжело обучать, если добавлять всё больше LSTM слоем, то снова встречаемся с проблемой затухающих градиентов, плюсом, всё равно нужно сжимать всю информацию в последние блоки - это наш bottleneck (узкое место, горлышко бутылки) между кодировщик и декодировщиком.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY_szeB8KpkH"
   },
   "source": [
    "И решение этой проблемы - Attention слой. Вместо того, чтобы сжимать всю информацию из всех временных ячеек в одно скрытое состояние, можно дать доступ декодировщику ко всей истории. Но получаем очень слишком много информации, которую нужно учитывать, поэтому мы будем обращать свое внимание только на подвыборку этих ячеек.\n",
    "\n",
    "Будем учитывать, какая часть предложения на английском языке важна для предсказания слова на французском языке. Подсчет такого распределения достигается получением оценки релевантности каждого слова в предложении для получения нового слова.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1GAVWyShMSXELaz1f-_e4c9rAeDoJ3QE_' width=450>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CKXDdDGOTB2"
   },
   "source": [
    "**Как использовать эти оценки релевантности?**\n",
    "\n",
    "Подсчитываются оценки для каждого скрытого состояния и образуют собой взвешанную сумму внимания. А потом эта сумма передается, как еще один вход в декодировщик.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1a72Ake6Ai2SdkZ9cQpqmq6-ebjblcQ34' width=450>\n",
    "\n",
    "Можно [провизуализировать](https://distill.pub/2016/augmented-rnns/#attentional-interfaces), какое внимание уделяется каждому слову из предложения:\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1OJ4vgTHPxGMzcR8Ob8An--FFUlnZabQ3' width=500>\n",
    "\n",
    "А ещё слои внимания можно добавлять и не только к текстам, но и к картинкам.\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1i48NmZMXUneeUwW339tSgvrGU_VvLh9H'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVZ6r22LPCou"
   },
   "source": [
    "## 4.2 Bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvTHVnyWp5EF"
   },
   "source": [
    "Из класса RNN есть еще интересный вариант [Bidirectional RNN](https://maxwell.ict.griffith.edu.au/spl/publications/papers/ieeesp97_schuster.pdf). Они позволяют видеть не только прошлое состояние, но и будущее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSqyTbwPp5EF"
   },
   "source": [
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1kCGsUWhUjIoIAquvE7FjaAbYjAQdsyW7' width=550>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmvdkWZ9p5EF"
   },
   "source": [
    "Общая идея: на каждом шаге есть и прямой проход и обратный. И векторы которые несут информацию из прошлого и будущего конкатенируются вместе и идут на выход с сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ_nFIPr3CBR"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "1. Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
    "\n",
    "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?\n",
    "\n",
    "У кого нет возможности работать через каггл (нет верификации), то можете данные взять по ссылке: https://disk.yandex.ru/d/LV1cYS1orMyRWA"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_Lesson_7.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
